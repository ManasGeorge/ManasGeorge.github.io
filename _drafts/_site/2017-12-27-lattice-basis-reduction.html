<h2 id="lattices">Lattices</h2>

<p>A lattice (not to be confused with a lettuce) is a subspace of the vector space <script type="math/tex">\mathbb{R}^n</script>; it is the closure of a set of vectors in that space under addition with integer coefficients. If that sounds like a mouthful, think of it as a set of evenly spaced grid points, like in the picture below. Given a basis of <script type="math/tex">n</script> linearly independent vectors <script type="math/tex">B = \{ b_1, b_2, \dots, b_n\}</script>, the lattice <script type="math/tex">L</script> that they span is defined as the set <script type="math/tex">\left \{ \sum\limits_{i=1}^n z_i b_i \vert z_i \in \mathbb{Z} \land b_i \in B \right \}</script>.</p>

<p>The diagram below depicts an example of a 2-dimensional lattice with basis vectors <script type="math/tex">% <![CDATA[
b_1 = \begin{bmatrix} 1.1 & 0.3 \end{bmatrix} %]]></script> and <script type="math/tex">% <![CDATA[
b_2 = \begin{bmatrix} 1.3 & 0.5 \end{bmatrix} %]]></script>. Not that the elements that make up the basis vectors themselves need not be integers.</p>

<p><img src="/assets/lattice.png" alt="lattice" /></p>

<p>Each of the other lattice points in blue is generated by some linear combination of these two basis vectors. The basis vectors for a given lattice are not unique. In particular, the two vectors in green form an alternate basis for the same lattice. You will notice that the green vectors are shorter and more orthogonal than the red vectors. It turns out having shorter, more orthogonal basis vectors given an arbitrary lattice makes it much easier to work with them, and indirectly lead to solutions to interesting problems. One interesting question, then, is whether there is a well-defined procedure that takes an arbitrary lattice basis and produce a shorter basis for the same lattice.</p>

<p>As a further motivating problem, suppose we would like to find out whether a certain number <script type="math/tex">r</script> is algebraic; that is, if it can be expressed as one of the roots to a polynomial of degree <script type="math/tex">n</script>. We use the lattice reducing method discussed here (the famous LLL algorithm) to find an equation such that one of its roots is <script type="math/tex">r</script>.</p>

<h2 id="the-2-dimensional-case">The 2-Dimensional Case</h2>

<p>It is easiest to start with the problem for two dimensions; we can readily visualize the vectors involved and rely on our intuition to guide us. Starting with the vectors <script type="math/tex">b_1</script> and <script type="math/tex">b_2</script>, we wish to reduce them as much as possible, resulting in the vectors <script type="math/tex">b^*_1</script> and <script type="math/tex">b^*_2</script>. How do we know when we are done? As a first pre-condition, let us require that <script type="math/tex">\lVert b^*_1 \rVert \le \lVert b^*_2 \rVert</script>. This imposes an ordering on the reduced basis vectors, which is nice to have. How do we know that we’ve reached the shortest possible vectors? Consider the operations we are allowed to perform on the basis without changing the span of the basis:</p>

<ul>
  <li>We can exchange two basis vectors; clearly this doesn’t change the span of the basis</li>
  <li>We can replace a basis vector by an integer linear combination of basis vectors</li>
</ul>

<p>The first operation lets us ensure that the vectors are in increasing order of their norms. The second lets us reduce the norms of the vectors by subtracting appropriate multiples of the other basis vector. Taking inspiration from Euclid’s algorithm for calculating the GCD of two numbers, we start by subtracting as many multiples of the smaller vector as possible from the larger one. Without loss of generality, assume <script type="math/tex">b_1</script> is the smaller vector (we can always exchange vectors to make this the case).</p>

<p>It turns out that taking the projection of the larger vector on to the smaller gives us the largest scalar multiple of the smaller vector we can subtract from the larger without increasing the norm of the resulting vector <sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>. Our first step, then is to update <script type="math/tex">b_2</script> as follows:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\mu_{12} &= \text{nint} \left( \frac{\langle b_1, b_2 \rangle}{\langle b_1, b_1 \rangle} \right) \\
b_2 &:= b_2 -  \mu_{12} b_1
\end{align*} %]]></script>

<p>Note that we do not use the projection directly; we must round to the nearest integer so that the resulting vector remains within the lattice. The new <script type="math/tex">b_2</script> will be smaller than <script type="math/tex">b_1</script>, so we exchange the two vectors and repeat the reduction process until it is no longer possible to reduce <script type="math/tex">b_2</script>.</p>

<p>This corresponds to the case where <script type="math/tex">% <![CDATA[
\left\vert \frac{\langle b_1, b_2 \rangle}{\langle b_1, b_1 \rangle} \right\vert < \frac{1}{2} %]]></script>, which means that the nearest integer is 0, implying that subtracting a multiple of <script type="math/tex">b_1</script> from <script type="math/tex">b_2</script> now can only make it bigger. At this point, we stop, ending up with vectors <script type="math/tex">b^*_1</script> and <script type="math/tex">b^*_2</script> that satisfy the conditions:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\left\Vert b^*_1 \right\Vert & \le \left\Vert b^*_2 \right\Vert \\
\left\vert \frac{\langle b^*_1, b^*_2 \rangle}{\langle b^*_1, b^*_1 \rangle} \right\vert & \le \frac{1}{2}
\end{align*} %]]></script>

<p>We take these conditions to be the definition of a reduced basis, since we cannot further reduce vectors satisfying these conditions using span-preserving operations.</p>

<h2 id="generalizing-to-higher-dimensions">Generalizing to higher dimensions</h2>

<h2 id="expressing-algebraic-numbers">Expressing algebraic numbers</h2>
<p>Consider <script type="math/tex">r = 0.222521</script>, which is just <script type="math/tex">\cos \left( \frac{3\pi}{7} \right)</script> rounded down to a few decimal places. Take the lattice in <script type="math/tex">\mathbb{R}^5</script> spanned by the following vectors:</p>

<script type="math/tex; mode=display">\left\{ \left[1, 0, 0, 0, 1000000r^3 \right], \left[0, 1, 0, 0, 1000000r^2 \right], \left[0, 0, 1, 0, 1000000r \right], \left[0, 0, 0, 1, 1000000 \right] \right\}</script>

<p>If we could find the shortest basis vector in this lattice, it would be some integer combination of the above, of the form <script type="math/tex">\left[a, b, c, d, 1000000(ar^3 + br^2 + cr + d) \right]</script>, with relatively small coefficients <script type="math/tex">a,b,c,d</script> and <script type="math/tex">ar^3 + br^2 + cr + d</script> even smaller (close to zero). Applying LLL, the lattice reduction algorithm that the rest of this post will talk about, we find that the shortest basis vector is <script type="math/tex">[8,-4,-4,1,0]</script>, which represents the equation <script type="math/tex">8x^3 - 4x^2 - 4x + 1</script>, one of whose roots is, indeed <script type="math/tex">\cos \left( \frac{3\pi}{7} \right)</script>. Interestingly enough, the other roots of the cubic found happen to be <script type="math/tex">\cos \left( \frac{5\pi}{7} \right)</script> and <script type="math/tex">\cos \left( \frac{\pi}{7} \right)</script>.</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Consider the inner product of a potentially reduced vector; <script type="math/tex">\langle b_2 - c b_1, b_2 - c b_1 \rangle = \langle b_2, b_2 \rangle - 2c \langle b_1, b_2 \rangle + c^2 \langle b_1, b_1 \rangle</script>. In order to minimize this expression, take the derivative of the inner product with respect to <script type="math/tex">c</script> and set it to zero, giving <script type="math/tex">-2 \langle b_1, b_2 \rangle + 2c \langle b_1, b_1 \rangle = 0 \implies c = \frac{\langle b_1, b_2 \rangle}{\langle b_1, b_1 \rangle}</script> <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
